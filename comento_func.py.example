import base64
import io
import json

import boto3
from PIL import Image
from openai import OpenAI

openai_client = OpenAI(api_key="KEY")

bedrock_client = boto3.client(
    service_name="bedrock-runtime",
    region_name="us-west-2",
    aws_access_key_id="KEY",
    aws_secret_access_key="KEY",
)

def openai_response(prompt):
    completion = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "You are a helpful but terse AI assistant who gets straight to the point.",
            },
            {"role": "user", "content": prompt},
        ],
        temperature=0.0,
    )
    response = completion.choices[0].message.content
    return response

# Model: Claude Sonnet v2.0
def claude_response(prompt):
    completion = bedrock_client.invoke_model(
        modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",
        body=json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 2048,
            "temperature": 0.0,
            "messages": [
                {
                    "role": "user",
                    "content": [{"type": "text", "text": prompt}],
                }
            ],
        })
    )

    response = json.loads(completion["body"].read())

    return response["content"][0]["text"]

# Model: Stable Diffusion 3.5 Large
# - At 8.1 billion parameters, with superior quality and prompt adherence, Stable Diffusion 3.5 Large is the most powerful model in the Stable Diffusion family. Ideal for professional use cases at 1-megapixel resolution, it is easily deployable at scale and allows users to securely deploy in their own virtual private cloud, ensuring their data remains safe and protected.
def stable_large(prompt):
    response = bedrock_client.invoke_model(
        modelId='stability.sd3-large-v1:0',
        body=json.dumps({
            'prompt': prompt
        })
    )

    output_body = json.loads(response["body"].read().decode("utf-8"))
    base64_output_image = output_body["images"][0]
    image_data = base64.b64decode(base64_output_image)
    image = Image.open(io.BytesIO(image_data))

    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    encoded_image = base64.b64encode(buffered.getvalue()).decode("utf-8")

    return encoded_image

# Model: Stable Image Core 1.0
# - Create and iterate images quickly and affordably with Stable Image Core, the image service that requires no prompt engineering to get high quality images in diverse styles at high speed.
def stable_core(prompt):
    response = bedrock_client.invoke_model(
        modelId='stability.stable-image-core-v1:1',
        body=json.dumps({
            'prompt': prompt
        })
    )

    output_body = json.loads(response["body"].read().decode("utf-8"))
    base64_output_image = output_body["images"][0]
    image_data = base64.b64decode(base64_output_image)
    image = Image.open(io.BytesIO(image_data))

    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    encoded_image = base64.b64encode(buffered.getvalue()).decode("utf-8")

    return encoded_image