import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
import re
import openai
from typing import Optional

from comento_func import openai_response

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="YouTube ì˜ìƒ ìš”ì•½", page_icon="ğŸ¥")
st.title("YouTube ì˜ìƒ ìš”ì•½ í”„ë¡œê·¸ë¨")

# YouTube URLì—ì„œ ì˜ìƒ IDë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_video_id(url: str) -> Optional[str]:
    video_id = None
    if 'youtu.be' in url:
        video_id = url.split('/')[-1]
    elif 'youtube.com' in url:
        match = re.search(r'v=([^&]*)', url)
        if match:
            video_id = match.group(1)
    return video_id


# ìë§‰ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def get_transcript(video_id: str) -> Optional[str]:
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko'])
        return ' '.join([t['text'] for t in transcript])
    except Exception as e:
        return None

# í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
def split_text(text: str, max_length: int = 4000) -> list:
    words = text.split()
    chunks = []
    current_chunk = []
    current_length = 0

    for word in words:
        if current_length + len(word) + 1 > max_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = [word]
            current_length = len(word)
        else:
            current_chunk.append(word)
            current_length += len(word) + 1

    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks


# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    st.write("YouTube ì˜ìƒì˜ URLì„ ì…ë ¥í•˜ë©´ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤.")

    # URL ì…ë ¥ ë°›ê¸°
    url = st.text_input("YouTube URLì„ ì…ë ¥í•˜ì„¸ìš”:")

    if url:
        try:
            # ì˜ìƒ ID ì¶”ì¶œ
            video_id = extract_video_id(url)
            if video_id:
                # ì˜ìƒ ì„ë² ë”© í‘œì‹œ
                st.video(url)

                # ìë§‰ ê°€ì ¸ì˜¤ê¸°
                transcript = get_transcript(video_id)

                if transcript:
                    st.subheader("ì˜ìƒ ìš”ì•½")
                    with st.spinner('ì˜ìƒì„ ìš”ì•½í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                        # ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
                        chunks = split_text(transcript)

                        # ê° ì²­í¬ì— ëŒ€í•´ ìš”ì•½ ìˆ˜í–‰
                        all_summaries = []
                        for chunk in chunks:
                            summary = openai_response(chunk)
                            all_summaries.append(summary)

                        # ì „ì²´ ìš”ì•½ í‘œì‹œ
                        final_summary = "\n\n".join(all_summaries)
                        st.markdown(final_summary)

                else:
                    st.error("ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒì— ìë§‰ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                st.error("ì˜¬ë°”ë¥¸ YouTube URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


if __name__ == "__main__":
    main()
